# GettingCleaningDataProject
This is a repo of all necessay elements of my final project for the Getting & Cleaning Data class on Coursera. It contains the following files:
* README.md: An explanation of the project, including details of the original dataset and the R script I wrote to clean it up and to generate a second, tidy dataset.
* run_analysis.R: The R script that cleans up the original dataset and generates a second, tidy dataset comprised of the averages of each mean and standard deviation variable for each suject and activity in the original dataset.
* CODEBOOK.md: An explanation of the variables in the dataset generated by my script.
* UCIHARAverageData.txt: A text file of the dataset generated by my script.

## The Project
The purpose of the project was to demonstrate my ability to collect, work with, and clean a data set, with the goal of preparing tidy data that can be used for later analysis. I accomplished this by writing an an R script (run_analysis.R) that: 1) downloads the original dataset, 2) merges all data, labels, and features into one table, 3) extracts only variables with mean and standard deviation measurements, 4) descriptively renames these variables, and 5) generates a new dataset with the average of each variable for each activity and each subject.

## The Data
The original data set is derived from experiments in Human Activity Recognition (HAR) conducted by Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto at Smartlab of the Univeristy of Genova, Italy.

The experiments were conducted with 30 volunteers, ranging in age from 19-48 years, each of whom performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) while wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, 3-axial linear acceleration and 3-axial angular velocity were captured at a constant rate of 50Hz. The experiments were video-recorded so the data could be manually labeled. The resulting dataset was randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The accelerometer and gyroscope signals were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals. The magnitude of these three-dimensional signals were also calculated using the Euclidean norm. Finally a Fast Fourier Transform (FFT) was applied to some of these signals to produce magnitude measurements. These signals were used to estimate variables of the feature vector for each pattern.

Each record provided:
* A subject identifier
* Activity labels
* Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration
* Triaxial angular velocity from the gyroscope
* A 561-feature vector with time and frequency domain variables

The dataset was comprised of the following files:
* README.txt: Explains how the experiemtns wered conducted and how data was gathered.
* features_info.txt: Shows information about the variables used on the feature vector.
* features.txt: List of all features.
* activity_labels.txt: Links the class labels with their activity name.
* train/X_train.txt: Training set.
* train/y_train.txt: Training labels.
* test/X_test.txt: Test set.
* test/y_test.txt: Test labels.
* train/subject_train.txt: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. 
* train/Inertial Signals/total_acc_x_train.txt: The acceleration signal from the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element vector. The same description applies for the 'total_acc_x_train.txt' and 'total_acc_z_train.txt' files for the Y and Z axis. 
* train/Inertial Signals/body_acc_x_train.txt: The body acceleration signal obtained by subtracting the gravity from the total acceleration. 
* train/Inertial Signals/body_gyro_x_train.txt: The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. 

A full description of the dataset can be found here:
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

The data can be found here:
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

**Reference:**  Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012.

## The Script
run_analysis.R performs the following steps:
1. Downloads and unzips the data files into a local directory using dir.create(), download.file(), setwd(), and unzip().
2. Reads the following files into tables using read.table():
* features.txt
* activity_labels.txt
* X_test.txt
* y_test.txt
* subject_test.txt
* X_train.txt
* y_train.txt
* subject_train.txt
3. Merges the test and train data tables using rbind() to create 3 data frames: xData, yData, and subjectData.
4. Extracts all variables with mean or standard deviation measurements using grep() and regular expression to locate features containing mean() or std() and subsetting them into xData.
5. Applies descriptive activity labels and variable names by 1) indexing the ativityLables table to the yData table; 2) using colnames() to names the subject and activity variables in subjectData and yData; and 3) and using colnames(), gsub(), and regular expressions to to substitute or remove parts of feature names (e.g. t=Time, f=Freq, remove - and ()).
6. Merges xData, yDta, and subjectData into one data frame using cbind().
7. Creates a new data frame with the average of each mean and standard deviation variable for each subject nd activity using ddply() and colMeans().
8. Writes the data frame to a file called ./data/UCIHARAverageData.txt in the local directory.
